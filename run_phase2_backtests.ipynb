{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAUBOT Phase 2: Comprehensive Backtesting\n",
    "\n",
    "This notebook runs all Phase 2 backtesting modules:\n",
    "1. Walk-Forward Optimization (7 folds)\n",
    "2. Monte Carlo Simulation (5K paths)\n",
    "3. Historical Stress Testing (8 events)\n",
    "4. Regime Analysis\n",
    "5. Reality Gap Testing (8 friction levels)\n",
    "\n",
    "Run all cells sequentially to complete Phase 2 validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set project root\n",
    "project_root = Path.cwd()\n",
    "if 'xaubot' not in str(project_root):\n",
    "    # Try to find xaubot directory\n",
    "    if (project_root / 'xaubot').exists():\n",
    "        project_root = project_root / 'xaubot'\n",
    "    elif (Path.home() / 'xaubot').exists():\n",
    "        project_root = Path.home() / 'xaubot'\n",
    "\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Walk-Forward Optimization (7 Folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_training.backtesting.walk_forward import WalkForwardOptimizer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"WALK-FORWARD OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "wfo = WalkForwardOptimizer(project_root)\n",
    "wfo_results = wfo.run_walk_forward()\n",
    "\n",
    "print(f\"\\nWFO Complete - Mean Accuracy: {wfo_results['wfo_score']['mean_accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo Simulation (5K Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_training.backtesting.monte_carlo import MonteCarloSimulator\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MONTE CARLO SIMULATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mc = MonteCarloSimulator(project_root)\n",
    "mc_results = mc.run_full_simulation()\n",
    "\n",
    "# Display key metrics\n",
    "shuffle = mc_results['methods']['shuffle']['metrics']\n",
    "print(f\"\\nMonte Carlo Complete:\")\n",
    "print(f\"  - Mean Return: {shuffle['total_return']['mean']*100:.1f}%\")\n",
    "print(f\"  - Mean Max DD: {shuffle['max_drawdown']['mean']*100:.1f}%\")\n",
    "print(f\"  - Risk of Ruin: {mc_results['methods']['shuffle']['risk_of_ruin']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Historical Stress Testing (8 Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_training.backtesting.stress_test import StressTester\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STRESS TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "st = StressTester(project_root)\n",
    "st_results = st.run_stress_test()\n",
    "\n",
    "print(f\"\\nStress Test Complete:\")\n",
    "print(f\"  - Events Passed: {st_results['summary']['events_passed']}/{st_results['summary']['events_tested']}\")\n",
    "print(f\"  - Survival Rate: {st_results['summary']['survival_rate']*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_training.backtesting.regime_analysis import RegimeAnalyzer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"REGIME ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ra = RegimeAnalyzer(project_root)\n",
    "ra_results = ra.run_regime_analysis()\n",
    "\n",
    "print(f\"\\nRegime Analysis Complete:\")\n",
    "for regime, data in ra_results['regime_results'].items():\n",
    "    if not regime.startswith('VOL_'):\n",
    "        print(f\"  - {regime}: {data['win_rate']*100:.1f}% WR, {data['profit_factor']:.2f} PF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reality Gap Testing (8 Friction Levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_training.backtesting.reality_gap import RealityGapTester\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"REALITY GAP TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rg = RealityGapTester(project_root)\n",
    "rg_results = rg.run_reality_gap_test()\n",
    "\n",
    "print(f\"\\nReality Gap Complete:\")\n",
    "print(f\"  - Baseline Return: {rg_results['baseline_return']*100:.1f}%\")\n",
    "print(f\"  - Final Level Return: {rg_results['final_level_return']*100:.1f}%\")\n",
    "print(f\"  - Still Profitable: {'Yes' if rg_results['final_level_profitable'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PHASE 2 BACKTESTING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Load all results\n",
    "results_dir = project_root / \"python_training\" / \"backtesting\" / \"results\"\n",
    "\n",
    "summary = {\n",
    "    \"Walk-Forward\": {\n",
    "        \"status\": \"PASS\" if wfo_results['wfo_score']['mean_accuracy'] > 0.55 else \"FAIL\",\n",
    "        \"metric\": f\"{wfo_results['wfo_score']['mean_accuracy']*100:.1f}% accuracy\"\n",
    "    },\n",
    "    \"Monte Carlo\": {\n",
    "        \"status\": \"PASS\" if shuffle['total_return']['mean'] > 0 else \"FAIL\",\n",
    "        \"metric\": f\"{shuffle['total_return']['mean']*100:.1f}% mean return\"\n",
    "    },\n",
    "    \"Stress Test\": {\n",
    "        \"status\": \"PASS\" if st_results['summary']['survival_rate'] >= 0.50 else \"FAIL\",\n",
    "        \"metric\": f\"{st_results['summary']['survival_rate']*100:.0f}% survival rate\"\n",
    "    },\n",
    "    \"Regime Analysis\": {\n",
    "        \"status\": \"PASS\",\n",
    "        \"metric\": \"All regimes analyzed\"\n",
    "    },\n",
    "    \"Reality Gap\": {\n",
    "        \"status\": \"PASS\" if rg_results['final_level_profitable'] else \"FAIL\",\n",
    "        \"metric\": f\"{rg_results['final_level_return']*100:.1f}% at full friction\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for test, data in summary.items():\n",
    "    icon = \"PASS\" if data['status'] == \"PASS\" else \"FAIL\"\n",
    "    print(f\"  [{icon}] {test}: {data['metric']}\")\n",
    "\n",
    "# Save combined results\n",
    "combined = {\n",
    "    \"run_date\": datetime.now().isoformat(),\n",
    "    \"summary\": summary,\n",
    "    \"wfo\": wfo_results['wfo_score'],\n",
    "    \"monte_carlo\": {\n",
    "        \"mean_return\": shuffle['total_return']['mean'],\n",
    "        \"mean_drawdown\": shuffle['max_drawdown']['mean'],\n",
    "        \"risk_of_ruin\": mc_results['methods']['shuffle']['risk_of_ruin']\n",
    "    },\n",
    "    \"stress_test\": st_results['summary'],\n",
    "    \"reality_gap\": {\n",
    "        \"baseline_return\": rg_results['baseline_return'],\n",
    "        \"final_return\": rg_results['final_level_return'],\n",
    "        \"profitable\": rg_results['final_level_profitable']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(results_dir / \"phase2_combined_results.json\", \"w\") as f:\n",
    "    json.dump(combined, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_dir / 'phase2_combined_results.json'}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 2 BACKTESTING COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
